---
title: "water-temp-bc"
output:
  html_document:
    code_folding: hide
    self_contained: true
params: 
  rmd_on: FALSE
  update_query: FALSE
---

```{r setup, echo=FALSE, include = TRUE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, dpi=60, out.width = "100%")

```


```{r, echo=FALSE, include = T}

staticimports::import()
source('scripts/staticimports.R')
source('scripts/functions.R')
```



```{r build, echo= FALSE, eval = FALSE}
rmarkdown::render(
  "README.Rmd", 
  output_format = "github_document", 
  params = list(rmd_on = FALSE)
  )

rmarkdown::render(
  "README.Rmd", 
  output_format = "html_document", 
  output_file = "index.html", 
  params = list(rmd_on = TRUE)
  )

usethis::use_git_ignore("README.html")
```

<!-- README.md is generated from README.Rmd. Please edit that file -->


![neeTo](https://img.shields.io/badge/status-neeTo-green)
![dEce](https://img.shields.io/badge/plays-dEce-red)


```{r fig, echo=FALSE, out.width="100%", fig.align="center", eval = TRUE}

fpr::fpr_photo_resize_convert("fig/cover.png", path = "fig")
knitr::include_graphics("fig/cover.JPG")
```


The goal of `water-temp-bc` is to document and serve out water temperature data. Setup and wrangle scripts are located here https://github.com/NewGraphEnvironment/water-temp-bc .  

<br>

We scrape the Environment Canada (ECCC) web service for all realtime temperature data for the province and serve it out from parquet files on s3 storage. We are however limited to around 18 months of data or so - so if we want current data we likely need to scrape
on a schedule and add the data to what we have. That said - ECCC has provided us with a ton of historic data so in `scripts/extract-eccc.R` we wrangle that together into one parquet file and serve on the cloud (s3 storage).

<br>

Currently we have more than 1 file so we we will need to put them all together soon. TO DO.  Here is a list of the files that we have currently with the date stamp corresponding to the latest date for water temperature data (there is also discharge and water level, air temp mixed in for some sites.)

```{r ls-files, eval = TRUE}

fs::dir_ls("data", glob = "*.parquet")
```


<br>


Using [`duckdb`](https://github.com/duckdb/duckdb-r) for `R` we are able to connect directly to the parquet files stored on a S3 bucket and query around to explore the provincial realtime data for the province of British Columbia.  The beauty of [`duckdb`](https://github.com/duckdb/duckdb-r) and the `parquet` file format (provided we install the `httpfs` extension) is that we don't need a database.  We just create a connection to a "virtual database" with the line below and we can query the files directly in the s3 buckets.... Neeto.

    con <- DBI::dbConnect(duckdb::duckdb())
    DBI::dbExecute(con, "INSTALL httpfs; LOAD httpfs;")



<br>

Currently the [data directory of this repo](https://github.com/NewGraphEnvironment/water-temp-bc/tree/main/data) is mirrored at s3://water-temp-bc/data so punch in any of the urls below into your browser and grab the files yourself.


<br>

In the code chunks below we connect to duckdb load the `httpfs` extension.

`r if (params$rmd_on == FALSE) "Please see http://www.newgraphenvironment.com/water-temp-bc for published table of collection links/details."`

```{r connect, results="asis", eval=TRUE}
con <- DBI::dbConnect(duckdb::duckdb())
DBI::dbExecute(con, "INSTALL httpfs; LOAD httpfs;")

```

<br>


In the next chunks we perform a couple of queries and present the information about the data currently available.
```{r q1}
tab <- DBI::dbGetQuery(
  con, 
  "SELECT *
  FROM 's3://water-temp-bc/data/stations_realtime.parquet'"
)
```

```{r q2, eval=params$update_query}
range <- DBI::dbGetQuery(con, "
  SELECT 
    STATION_NUMBER,
    MIN(Date) AS min_date,
    MAX(Date) AS max_date
  FROM 's3://water-temp-bc/data/realtime_raw_20250521.parquet'
  WHERE Parameter = '5'
  GROUP BY STATION_NUMBER;
")

# save local so need not run every time
saveRDS(range, "data/result.rds")
```

```{r stations-cap, echo=FALSE, results="asis", eval=identical(params$rmd_on, TRUE)}
my_caption <- "Realtime station information stored on AWS s3."

my_tab_caption_rmd()
```



```{r tab-stations, echo=FALSE, eval=identical(params$rmd_on, TRUE)}

range <- readRDS("data/result.rds")

dplyr::left_join(
  tab,
  range,
  by = "STATION_NUMBER"
  )|> 
  my_dt_table(cols_freeze_left = 2, escape = FALSE)
```


<br>

Below we query for data from a particular site. Note that Parameter = '5' seems to be a better query than
Code = "TW" since not all events are currently labelled with a Code...

<br> 

```{r q3}
tab <- DBI::dbGetQuery(con, "
  SELECT *
  FROM 's3://water-temp-bc/data/realtime_raw_20250521.parquet'
  WHERE STATION_NUMBER IN ('07EA004')
    AND Parameter = '5' 
    LIMIT 100
")
```


```{r tab-uav-imagery-cap, echo=FALSE, results="asis", eval=identical(params$rmd_on, TRUE)}
my_caption <- "Example of output generated by querying parquet file stored on AWS s3."

my_tab_caption_rmd()
```


```{r example, echo=FALSE, eval=identical(params$rmd_on, TRUE)}
tab |> 
  my_dt_table(cols_freeze_left = 2, escape = FALSE)
```

```{r db-disconnect}
DBI::dbDisconnect(conn = con)
```



